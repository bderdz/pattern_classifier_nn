{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T19:41:22.178652Z",
     "start_time": "2025-06-14T19:41:22.176250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import numpy.typing as npt\n"
   ],
   "id": "92d1c0f6776ba3c3",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T19:41:22.188300Z",
     "start_time": "2025-06-14T19:41:22.185243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sigmoid(z: npt.NDArray) -> npt.NDArray:\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def sigmoid_derivative(z: npt.NDArray) -> npt.NDArray:\n",
    "    sig = sigmoid(z)\n",
    "    return sig * (1 - sigmoid(z))\n",
    "\n",
    "\n",
    "def softmax(z: npt.NDArray) -> npt.NDArray:\n",
    "    z = np.array(z)\n",
    "    exp_z = np.exp(z - np.max(z))\n",
    "    return exp_z / np.sum(exp_z)\n",
    "\n",
    "\n",
    "def relu(z: npt.NDArray) -> npt.NDArray:\n",
    "    return np.maximum(0, z)\n",
    "\n",
    "\n",
    "def relu_derivative(z: npt.NDArray) -> npt.NDArray:\n",
    "    return (z > 0).astype(float)"
   ],
   "id": "683854aa74c10d58",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cross_entropy(y_pred: npt.NDArray, y_target: npt.NDArray) -> float:\n",
    "    return -np.sum(y_target * np.log(y_pred + 1e-15))"
   ],
   "id": "16447d2b3578bf83"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T19:41:22.198919Z",
     "start_time": "2025-06-14T19:41:22.196410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Layer:\n",
    "    def __init__(self, input_dim: int, units: int, activation, activation_deriv):\n",
    "        self.activation = activation\n",
    "        self.activation_deriv = activation_deriv\n",
    "        self.W = np.random.rand(units, input_dim) * 0.1\n",
    "        self.b = np.zeros((units, 1))\n",
    "\n",
    "    def forward(self, x: npt.NDArray) -> npt.NDArray:\n",
    "        self.x = x\n",
    "        self.z = self.W @ x + self.b\n",
    "        self.a = self.activation(self.z)\n",
    "\n",
    "        return self.a\n",
    "\n",
    "    def backward(self, grad_output: npt.NDArray, learning_rate: float) -> npt.NDArray:\n",
    "        dz = grad_output * self.activation_deriv(self.z)\n"
   ],
   "id": "11172fb8618195fb",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-14T19:41:22.212678Z",
     "start_time": "2025-06-14T19:41:22.208563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers: list[Layer]):\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x: npt.NDArray) -> npt.NDArray:\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output: npt.NDArray, learning_rate: float) -> None:\n",
    "        for layer in reversed(self.layers):\n",
    "            grad_output = layer.backward(grad_output, learning_rate)\n",
    "\n",
    "    def train(self, train_x: npt.NDArray, train_y: npt.NDArray, epochs: int, learning_rate: float) -> None:\n",
    "        for epoch in range(epochs):\n",
    "            total_loss: float = 0.\n",
    "\n",
    "            for x, y in zip(train_x, train_y):\n",
    "                # Reshaping to column vector.\n",
    "                x: npt.NDArray = x.reshape(-1, 1)\n",
    "                y: npt.NDArray = y.reshape(-1, 1)\n",
    "                # Forward pass\n",
    "                output = self.forward(x)\n",
    "                # Loss\n",
    "                loss = cross_entropy(output, y)\n",
    "                total_loss += loss\n",
    "                # Backpropagation\n",
    "                grad_output = output - y\n",
    "                self.backward(grad_output, learning_rate)\n",
    "\n",
    "            print(f\"Epoch {epoch}: loss = {total_loss}\")\n",
    "\n",
    "    def predict(self):\n",
    "        ..."
   ],
   "id": "cbc114890cf3823e",
   "outputs": [],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
